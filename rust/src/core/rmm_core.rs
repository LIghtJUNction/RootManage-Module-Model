use anyhow::{Context, Result};
use git2::{Repository, StatusOptions};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::env;
use std::fs;
use std::path::{Path, PathBuf};
use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant};
use toml;
use walkdir::WalkDir;

/// ç¼“å­˜é¡¹ç»“æ„
#[derive(Debug, Clone)]
#[allow(dead_code)]
struct CacheItem<T> {
    data: T,
    #[allow(dead_code)]
    timestamp: Instant,
    expires_at: Instant,
}

impl<T> CacheItem<T> {
    fn new(data: T, ttl: Duration) -> Self {
        let now = Instant::now();
        Self {
            data,
            timestamp: now,
            expires_at: now + ttl,
        }
    }

    fn is_expired(&self) -> bool {
        Instant::now() > self.expires_at
    }
}

/// Meta.toml æ–‡ä»¶ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct MetaConfig {
    pub email: String,
    pub username: String,
    pub version: String,
    pub projects: HashMap<String, String>,
}

/// RmmProject.toml æ–‡ä»¶ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct RmmProject {
    pub project: ProjectInfo,
    pub authors: Vec<Author>,
    pub urls: Option<UrlsInfo>,
    #[serde(rename = "build-system")]
    pub build_system: Option<BuildSystem>,
    #[serde(rename = "tool")]
    pub tool: Option<HashMap<String, toml::Value>>,
}

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct ProjectInfo {
    pub id: String,
    pub description: String,
    pub readme: String,
    pub changelog: String,
    pub license: String,
    pub dependencies: Vec<String>,
    pub scripts: Option<HashMap<String, String>>,
}

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct Author {
    pub name: String,
    pub email: String,
}

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct UrlsInfo {
    pub github: String,
}

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct BuildSystem {
    pub requires: Vec<String>,
    #[serde(rename = "build-backend")]
    pub build_backend: String,
}

/// Module.prop æ–‡ä»¶ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct ModuleProp {
    pub id: String,
    pub name: String,
    pub version: String,
    #[serde(rename = "versionCode")]
    pub version_code: String,
    pub author: String,
    pub description: String,
    #[serde(rename = "updateJson")]
    pub update_json: String,
}

/// Rmake.toml æ–‡ä»¶ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct RmakeConfig {
    pub build: BuildConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct BuildConfig {
    pub include: Vec<String>,
    pub exclude: Vec<String>,
    pub prebuild: Vec<String>,
    pub build: Vec<String>,
    pub postbuild: Vec<String>,
    pub src: Option<SrcConfig>,
    pub scripts: Option<HashMap<String, String>>,
}

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct SrcConfig {
    pub include: Vec<String>,
    pub exclude: Vec<String>,
}

/// é¡¹ç›®æ‰«æç»“æœ
#[derive(Debug, Clone)]
pub struct ProjectScanResult {
    pub name: String,
    pub path: PathBuf,
    pub is_valid: bool,
    #[allow(dead_code)]
    pub git_info: Option<GitInfo>,
}

/// Git ä»“åº“ä¿¡æ¯
#[derive(Debug, Clone, PartialEq, Default)]
pub struct GitInfo {
    pub repo_root: PathBuf,
    pub relative_path: PathBuf,
    pub branch: String,
    pub remote_url: Option<String>,
    pub has_uncommitted_changes: bool,
    pub last_commit_hash: Option<String>,
    pub last_commit_message: Option<String>,
}

/// Git åˆ†æå™¨
pub struct GitAnalyzer;

impl GitAnalyzer {
    /// åˆ†æç»™å®šè·¯å¾„çš„ Git ä¿¡æ¯
    pub fn analyze_git_info(path: &Path) -> Result<Option<GitInfo>> {
        let git_root = Self::find_git_root(path)?;
        
        if let Some(repo_root) = git_root {
            let repo = Repository::open(&repo_root)
                .with_context(|| format!("Failed to open Git repository at {}", repo_root.display()))?;
            
            let relative_path = path.strip_prefix(&repo_root)
                .unwrap_or(Path::new(""))
                .to_path_buf();
            
            let branch = Self::get_current_branch(&repo)?;
            let remote_url = Self::get_remote_url(&repo)?;
            let has_uncommitted_changes = Self::has_uncommitted_changes(&repo)?;
            let (last_commit_hash, last_commit_message) = Self::get_last_commit_info(&repo)?;
            
            Ok(Some(GitInfo {
                repo_root,
                relative_path,
                branch,
                remote_url,
                has_uncommitted_changes,
                last_commit_hash,
                last_commit_message,
            }))
        } else {
            Ok(None)
        }
    }
    
    /// æŸ¥æ‰¾ Git æ ¹ç›®å½•
    pub fn find_git_root(path: &Path) -> Result<Option<PathBuf>> {
        let mut current = path.to_path_buf();
        
        loop {
            let git_dir = current.join(".git");
            if git_dir.exists() {
                return Ok(Some(current));
            }
            
            if let Some(parent) = current.parent() {
                current = parent.to_path_buf();
            } else {
                break;
            }
        }
        
        Ok(None)
    }
    
    /// è·å–å½“å‰åˆ†æ”¯å
    fn get_current_branch(repo: &Repository) -> Result<String> {
        let head = repo.head()
            .with_context(|| "Failed to get HEAD reference")?;
        
        if let Some(branch_name) = head.shorthand() {
            Ok(branch_name.to_string())
        } else {
            Ok("HEAD".to_string())
        }
    }
    
    /// è·å–è¿œç¨‹ä»“åº“ URL
    fn get_remote_url(repo: &Repository) -> Result<Option<String>> {
        let remotes = repo.remotes()
            .with_context(|| "Failed to get remotes")?;
        
        if let Some(remote_name) = remotes.get(0) {
            let remote = repo.find_remote(remote_name)
                .with_context(|| format!("Failed to find remote: {}", remote_name))?;
            
            if let Some(url) = remote.url() {
                return Ok(Some(url.to_string()));
            }
        }
        
        Ok(None)
    }
    
    /// æ£€æŸ¥æ˜¯å¦æœ‰æœªæäº¤çš„æ›´æ”¹
    fn has_uncommitted_changes(repo: &Repository) -> Result<bool> {
        let mut opts = StatusOptions::new();
        opts.include_ignored(false);
        opts.include_untracked(true);
        
        let statuses = repo.statuses(Some(&mut opts))
            .with_context(|| "Failed to get repository status")?;
        
        Ok(!statuses.is_empty())
    }
      /// è·å–æœ€åä¸€æ¬¡æäº¤ä¿¡æ¯
    fn get_last_commit_info(repo: &Repository) -> Result<(Option<String>, Option<String>)> {
        // ğŸ”§ ä¿®å¤ï¼šä¼˜é›…å¤„ç†ç©ºä»“åº“å’ŒHEADä¸ºç©ºçš„æƒ…å†µ
        match repo.head() {
            Ok(head) => {
                if let Some(oid) = head.target() {
                    match repo.find_commit(oid) {
                        Ok(commit) => {
                            let hash = oid.to_string();
                            let message = commit.message().unwrap_or("").to_string();
                            Ok((Some(hash), Some(message)))
                        }
                        Err(_) => {
                            // æäº¤å¯¹è±¡ä¸å­˜åœ¨ï¼Œå¯èƒ½æ˜¯ç©ºä»“åº“
                            Ok((None, None))
                        }
                    }
                } else {
                    // HEADå­˜åœ¨ä½†æ²¡æœ‰æŒ‡å‘ä»»ä½•æäº¤ï¼ˆç©ºä»“åº“ï¼‰
                    Ok((None, None))
                }
            }
            Err(_) => {
                // HEADä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®ï¼ˆå¾ˆå¯èƒ½æ˜¯ç©ºä»“åº“æˆ–æŸåçš„ä»“åº“ï¼‰
                Ok((None, None))
            }
        }
    }
}

/// RmmCore ä¸»è¦ç»“æ„ä½“
#[derive(Debug)]
pub struct RmmCore {
    rmm_root: PathBuf,
    meta_cache: Arc<Mutex<Option<CacheItem<MetaConfig>>>>,
    project_cache: Arc<Mutex<HashMap<String, CacheItem<RmmProject>>>>,
    cache_ttl: Duration,
    /// Git ä¿¡æ¯ç¼“å­˜
    git_cache: Arc<Mutex<HashMap<PathBuf, (GitInfo, Instant)>>>,

}

impl RmmCore {    /// åˆ›å»ºæ–°çš„ RmmCore å®ä¾‹
    pub fn new() -> Self {
        Self {
            rmm_root: Self::get_rmm_root_path(),
            meta_cache: Arc::new(Mutex::new(None)),
            project_cache: Arc::new(Mutex::new(HashMap::new())),
            cache_ttl: Duration::from_secs(60), // 60ç§’ç¼“å­˜
            git_cache: Arc::new(Mutex::new(HashMap::new())),
        }
    }

    /// åŠŸèƒ½ä¸€ï¼šè·å– RMM_ROOT è·¯å¾„
    /// å°è¯•è¯»å–ç¯å¢ƒå˜é‡ RMM_ROOTï¼Œå¦‚æœæ²¡æœ‰è¿”å›é»˜è®¤å€¼ï¼š~/data/adb/.rmm/
    pub fn get_rmm_root(&self) -> PathBuf {
        self.rmm_root.clone()
    }    fn get_rmm_root_path() -> PathBuf {
        if let Ok(root) = env::var("RMM_ROOT") {
            PathBuf::from(root)
        } else {
            let home = env::var("HOME")
                .or_else(|_| env::var("USERPROFILE"))
                .unwrap_or_else(|_| String::from("."));
            // ç¡®ä¿è·¯å¾„æ„å»ºçš„æ­£ç¡®æ€§ï¼Œå¼ºåˆ¶é‡æ–°æ„å»ºè·¯å¾„å­—ç¬¦ä¸²
            let mut path = PathBuf::from(home);
            path.push("data");
            path.push("adb");
            path.push(".rmm");
            path
        }
    }

    /// è·å– meta.toml æ–‡ä»¶è·¯å¾„
    fn get_meta_path(&self) -> PathBuf {
        self.rmm_root.join("meta.toml")
    }    /// åŠŸèƒ½äºŒï¼šè·å– RMM_ROOT/meta.toml æ–‡ä»¶çš„å†…å®¹ï¼ˆè§£æä¸ºå­—å…¸ï¼‰
    pub fn get_meta_config(&self) -> Result<MetaConfig> {
        // ğŸ”§ ä¿®å¤ï¼šé¿å…å¤šæ¬¡è·å–é”ï¼Œé˜²æ­¢æ­»é”
        let need_reload = {
            let cache = self.meta_cache.lock().unwrap();
            match cache.as_ref() {
                Some(cached) if !cached.is_expired() => {
                    return Ok(cached.data.clone());
                }
                _ => true, // éœ€è¦é‡è½½
            }
        };

        if need_reload {
            // è¯»å–å¹¶è§£ææ–‡ä»¶
            let meta_path = self.get_meta_path();
            let content = fs::read_to_string(&meta_path)
                .with_context(|| format!("Failed to read meta.toml from {}", meta_path.display()))?;
            
            let meta: MetaConfig = toml::from_str(&content)
                .with_context(|| "Failed to parse meta.toml")?;

            // ğŸ”§ ä¿®å¤ï¼šå•æ¬¡è·å–é”å¹¶æ›´æ–°ç¼“å­˜
            {
                let mut cache = self.meta_cache.lock().unwrap();
                *cache = Some(CacheItem::new(meta.clone(), self.cache_ttl));
            }

            Ok(meta)
        } else {
            // è¿™ä¸ªåˆ†æ”¯å®é™…ä¸Šä¸ä¼šæ‰§è¡Œåˆ°ï¼Œä½†ä¸ºäº†å®Œå¤‡æ€§ä¿ç•™
            unreachable!("Cache check should have returned early")
        }
    }    /// åŠŸèƒ½ä¸‰ï¼šæ›´æ–° meta.toml æ–‡ä»¶çš„å†…å®¹
    pub fn update_meta_config(&self, meta: &MetaConfig) -> Result<()> {
        let meta_path = self.get_meta_path();
        
        // ç¡®ä¿ç›®å½•å­˜åœ¨
        if let Some(parent) = meta_path.parent() {
            fs::create_dir_all(parent)
                .with_context(|| format!("Failed to create directory {}", parent.display()))?;
        }

        let content = toml::to_string_pretty(meta)
            .with_context(|| "Failed to serialize meta config")?;
        
        // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ä¸´æ—¶æ–‡ä»¶å’ŒåŸå­æ€§å†™å…¥ï¼Œé¿å…å¹¶å‘å†™å…¥ç«äº‰æ¡ä»¶
        let temp_path = meta_path.with_extension("toml.tmp");
        
        // å†™å…¥ä¸´æ—¶æ–‡ä»¶
        fs::write(&temp_path, &content)
            .with_context(|| format!("Failed to write temporary meta.toml to {}", temp_path.display()))?;
        
        // åŸå­æ€§é‡å‘½åï¼Œç¡®ä¿å¹¶å‘å®‰å…¨
        fs::rename(&temp_path, &meta_path)
            .with_context(|| format!("Failed to rename temporary file to {}", meta_path.display()))?;

        // æ›´æ–°ç¼“å­˜
        {
            let mut cache = self.meta_cache.lock().unwrap();
            *cache = Some(CacheItem::new(meta.clone(), self.cache_ttl));
        }

        Ok(())
    }

    /// åŠŸèƒ½å››ï¼šè¿”å› meta.toml æ–‡ä»¶å†…å®¹çš„æŸä¸ªé”®çš„å€¼
    #[allow(dead_code)]
    pub fn get_meta_value(&self, key: &str) -> Result<Option<toml::Value>> {
        let meta_path = self.get_meta_path();
        let content = fs::read_to_string(&meta_path)
            .with_context(|| format!("Failed to read meta.toml from {}", meta_path.display()))?;
        
        let parsed: toml::Value = toml::from_str(&content)
            .with_context(|| "Failed to parse meta.toml")?;

        Ok(parsed.get(key).cloned())
    }    /// åŠŸèƒ½äº”ï¼šç»™å®šé¡¹ç›®åï¼Œè¿”å›è·¯å¾„
    pub fn get_project_path(&self, project_name: &str) -> Result<Option<PathBuf>> {
        let meta = self.get_meta_config()?;
        Ok(meta.projects.get(project_name).map(|p| PathBuf::from(p)))
    }

    /// åŠŸèƒ½å…­ï¼šæ£€æŸ¥å„ä¸ªé¡¹ç›®æ˜¯å¦æœ‰æ•ˆï¼ˆåˆ¤æ–­å¯¹åº”æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨ä¸”åŒ…å« rmmproject.toml æ–‡ä»¶ï¼‰
    pub fn check_projects_validity(&self) -> Result<HashMap<String, bool>> {
        let meta = self.get_meta_config()?;
        let mut results = HashMap::new();
        let mut canonical_paths = std::collections::HashSet::new();

        for (name, path) in &meta.projects {
            let project_path = PathBuf::from(path);
            
            // 1. æ£€æŸ¥é¡¹ç›®åç§°æ˜¯å¦ç¬¦åˆè§„èŒƒ
            let name_valid = is_valid_project_name(name);
            if !name_valid {
                #[cfg(debug_assertions)]
                eprintln!("âŒ é¡¹ç›®åç§° '{}' ä¸ç¬¦åˆè§„èŒƒ", name);
                results.insert(name.clone(), false);
                continue;
            }
              // 2. é»‘åå•æ£€æŸ¥ - æ’é™¤æ„å»ºç›¸å…³ç›®å½•å’Œç³»ç»Ÿç›®å½•
            let blacklisted_names = [
                // æ„å»ºå’Œå¼€å‘ç›¸å…³ç›®å½•
                "build", "source-build", "dist", "target", "node_modules", 
                ".git", ".vscode", "tmp", "temp", "cache", "output",
                ".rmmp", "out", "bin", "obj", ".next", "coverage",
                // ğŸ”§ ä¿®å¤ï¼šå¢åŠ æ›´å®Œæ•´çš„ç³»ç»Ÿç›®å½•é»‘åå•
                "System32", "Windows", "Program Files", "Program Files (x86)",
                "usr", "var", "etc", "proc", "sys", "dev", "boot", "mnt",
                "AppData", "Application Data", "Documents and Settings",
                // åŒ…ç®¡ç†å™¨å’Œè™šæ‹Ÿç¯å¢ƒç›®å½•
                "venv", ".venv", "env", ".env", "__pycache__", ".pytest_cache",
                "vendor", "packages", ".nuget", ".gradle", ".m2",
                // ç¼–è¾‘å™¨å’ŒIDEç›®å½•
                ".idea", ".vs", ".vscode", ".sublime-workspace", ".atom",
                // æ—¥å¿—å’Œä¸´æ—¶æ–‡ä»¶ç›®å½•
                "logs", "log", "Temp", "temporary", "TEMP", "TMP"
            ];
            if blacklisted_names.contains(&name.as_str()) {
                #[cfg(debug_assertions)]
                eprintln!("ğŸš« é¡¹ç›®åç§° '{}' åœ¨é»‘åå•ä¸­", name);
                results.insert(name.clone(), false);
                continue;
            }
            
            // 3. æ£€æŸ¥è·¯å¾„æ˜¯å¦ä¸º .rmmp çš„å­ç›®å½•ï¼ˆæ„å»ºäº§ç‰©ï¼‰
            if project_path.ancestors().any(|ancestor| {
                ancestor.file_name().map_or(false, |name| name == ".rmmp")
            }) {
                #[cfg(debug_assertions)]
                eprintln!("ğŸš« é¡¹ç›®è·¯å¾„ '{}' ä½äº .rmmp æ„å»ºç›®å½•ä¸‹", path);
                results.insert(name.clone(), false);
                continue;
            }
            
            // 4. æ£€æŸ¥é¡¹ç›®è·¯å¾„å’Œæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            let path_valid = project_path.exists() && 
                           project_path.is_dir() && 
                           project_path.join("rmmproject.toml").exists() &&
                           project_path.join(".rmmp").exists() &&
                           project_path.join(".rmmp").join("Rmake.toml").exists();
            
            if !path_valid {
                #[cfg(debug_assertions)]
                eprintln!("âŒ é¡¹ç›®è·¯å¾„ '{}' æ— æ•ˆæˆ–ç¼ºå°‘å¿…è¦æ–‡ä»¶", path);
                results.insert(name.clone(), false);
                continue;
            }
            
            // 5. æ£€æŸ¥è·¯å¾„é‡å¤ï¼ˆä½¿ç”¨ canonicalize è§£æçœŸå®è·¯å¾„ï¼‰
            if let Ok(canonical_path) = project_path.canonicalize() {
                if canonical_paths.contains(&canonical_path) {
                    #[cfg(debug_assertions)]
                    eprintln!("ğŸš« é¡¹ç›® '{}' è·¯å¾„é‡å¤: {}", name, canonical_path.display());
                    results.insert(name.clone(), false);
                    continue;
                }
                canonical_paths.insert(canonical_path);
            }
            
            // æ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡
            results.insert(name.clone(), true);
        }

        Ok(results)
    }    /// åŠŸèƒ½ä¸ƒï¼šç»™å®šä¸€ä¸ªè·¯å¾„å’Œéå†æ·±åº¦ï¼Œæ‰«æè·¯å¾„ä¸‹æ˜¯å¦å«æœ‰ rmmp(project)
    pub fn scan_projects(&self, scan_path: &Path, max_depth: Option<usize>) -> Result<Vec<ProjectScanResult>> {
        let mut results = Vec::new();
        let mut canonical_paths = std::collections::HashSet::new(); // é˜²æ­¢é‡å¤è·¯å¾„
        
        let walker = if let Some(depth) = max_depth {
            WalkDir::new(scan_path).max_depth(depth)
        } else {
            WalkDir::new(scan_path)
        };
        
        for entry in walker.into_iter().filter_map(|e| e.ok()) {
            let path = entry.path();
            
            // è·³è¿‡ .rmmp ç›®å½•ä¸‹çš„æ‰€æœ‰å­ç›®å½•ï¼ˆè¿™äº›æ˜¯æ„å»ºäº§ç‰©ï¼‰
            if path.ancestors().any(|ancestor| {
                ancestor.file_name().map_or(false, |name| name == ".rmmp")
            }) {
                #[cfg(debug_assertions)]
                eprintln!("â­ï¸  è·³è¿‡ .rmmp ç›®å½•ä¸‹çš„è·¯å¾„: {}", path.display());
                continue;
            }
              // æ£€æŸ¥æ˜¯å¦åŒ…å« rmmproject.toml
            let project_file = path.join("rmmproject.toml");
            if project_file.exists() {
                // ğŸ”§ ä¿®å¤ï¼šæ”¹è¿›è·¯å¾„è§„èŒƒåŒ–é”™è¯¯å¤„ç†é€»è¾‘
                let canonical_path = match path.canonicalize() {
                    Ok(p) => p,
                    Err(e) => {
                        #[cfg(debug_assertions)]
                        eprintln!("âš ï¸  è·¯å¾„è§„èŒƒåŒ–å¤±è´¥ {} ({}), ä½¿ç”¨åŸå§‹è·¯å¾„", path.display(), e);
                        // ğŸ”§ ä¿®å¤ï¼šä¸ç›´æ¥è·³è¿‡ï¼Œè€Œæ˜¯ä½¿ç”¨åŸå§‹è·¯å¾„ä½†æ ‡è®°ä¸ºæ½œåœ¨é‡å¤
                        path.to_path_buf()
                    }
                };
                  // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨è·¯å¾„å­—ç¬¦ä¸²è¿›è¡Œé‡å¤æ£€æŸ¥ï¼Œä»¥å¤„ç†è§„èŒƒåŒ–å¤±è´¥çš„æƒ…å†µ
                if canonical_paths.contains(&canonical_path) {
                    #[cfg(debug_assertions)]
                    eprintln!("â­ï¸  è·³è¿‡é‡å¤è·¯å¾„: {} (canonical: {})", path.display(), canonical_path.display());
                    continue;
                }
                
                let name = canonical_path.file_name()
                    .and_then(|n| n.to_str())
                    .unwrap_or("unknown")
                    .to_string();
                
                // è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°æ­£åœ¨éªŒè¯çš„é¡¹ç›®åç§°
                #[cfg(debug_assertions)]
                eprintln!("ğŸ” æ­£åœ¨éªŒè¯é¡¹ç›®åç§°: '{}' åœ¨è·¯å¾„: {} (canonical: {})", name, path.display(), canonical_path.display());
                  // é»‘åå•æ£€æŸ¥ - æ’é™¤æ„å»ºç›¸å…³ç›®å½•
                let blacklisted_names = [
                    // æ„å»ºå’Œå¼€å‘ç›¸å…³ç›®å½•
                    "build", "source-build", "dist", "target", "node_modules", 
                    ".git", ".vscode", "tmp", "temp", "cache", "output",
                    ".rmmp", "out", "bin", "obj", ".next", "coverage",
                    // ğŸ”§ ä¿®å¤ï¼šå¢åŠ æ›´å®Œæ•´çš„ç³»ç»Ÿç›®å½•é»‘åå•
                    "System32", "Windows", "Program Files", "Program Files (x86)",
                    "usr", "var", "etc", "proc", "sys", "dev", "boot", "mnt",
                    "AppData", "Application Data", "Documents and Settings",
                    // åŒ…ç®¡ç†å™¨å’Œè™šæ‹Ÿç¯å¢ƒç›®å½•
                    "venv", ".venv", "env", ".env", "__pycache__", ".pytest_cache",
                    "vendor", "packages", ".nuget", ".gradle", ".m2",
                    // ç¼–è¾‘å™¨å’ŒIDEç›®å½•
                    ".idea", ".vs", ".vscode", ".sublime-workspace", ".atom",
                    // æ—¥å¿—å’Œä¸´æ—¶æ–‡ä»¶ç›®å½•
                    "logs", "log", "Temp", "temporary", "TEMP", "TMP"
                ];
                if blacklisted_names.contains(&name.as_str()) {
                    #[cfg(debug_assertions)]
                    eprintln!("ğŸš« é¡¹ç›®åç§° '{}' åœ¨é»‘åå•ä¸­ï¼Œè·³è¿‡", name);
                    continue;
                }
                
                // éªŒè¯é¡¹ç›®åç§°æ ¼å¼ï¼šå¿…é¡»ç¬¦åˆ ^[a-zA-Z][a-zA-Z0-9._-]+$
                if !is_valid_project_name(&name) {
                    #[cfg(debug_assertions)]
                    eprintln!("âŒ é¡¹ç›®åç§° '{}' ä¸ç¬¦åˆå‘½åè§„åˆ™ï¼Œè·³è¿‡", name);
                    continue; // è·³è¿‡ä¸ç¬¦åˆå‘½åè§„åˆ™çš„é¡¹ç›®
                }
                
                #[cfg(debug_assertions)]
                eprintln!("âœ… é¡¹ç›®åç§° '{}' éªŒè¯é€šè¿‡", name);
                
                // æ£€æŸ¥æ˜¯å¦æ˜¯å®Œæ•´çš„ RMM é¡¹ç›®
                let rmmp_dir = path.join(".rmmp");
                let rmake_file = rmmp_dir.join("Rmake.toml");
                let is_valid = rmmp_dir.exists() && rmake_file.exists();
                
                // è·å– Git ä¿¡æ¯
                let git_info = GitAnalyzer::analyze_git_info(path).ok().flatten();
                
                // è®°å½•è¿™ä¸ªè·¯å¾„ä»¥é˜²é‡å¤
                canonical_paths.insert(canonical_path.clone());
                
                results.push(ProjectScanResult {
                    name,
                    path: canonical_path, // ä½¿ç”¨æ ‡å‡†åŒ–çš„è·¯å¾„
                    is_valid,
                    git_info,
                });
            }
        }

        Ok(results)
    }

    /// åŠŸèƒ½å…«ï¼šåŒå‘æ›´æ–°é¡¹ç›®åˆ—è¡¨ï¼ˆå°†æ‰«æç»“æœåŒæ­¥åˆ° meta.tomlï¼‰
    pub fn sync_projects(&self, scan_paths: &[&Path], max_depth: Option<usize>) -> Result<()> {
        let mut all_projects = HashMap::new();
        
        // æ‰«ææ‰€æœ‰è·¯å¾„
        for &scan_path in scan_paths {
            let scanned = self.scan_projects(scan_path, max_depth)?;
            for project in scanned {
                all_projects.insert(project.name, project.path.to_string_lossy().to_string());
            }
        }

        // è·å–å½“å‰é…ç½®
        let mut meta = self.get_meta_config().unwrap_or_else(|_| MetaConfig {
            email: String::new(),
            username: String::new(),
            version: String::new(),
            projects: HashMap::new(),
        });

        // æ›´æ–°é¡¹ç›®åˆ—è¡¨
        meta.projects.extend(all_projects);

        // ä¿å­˜æ›´æ–°
        self.update_meta_config(&meta)?;

        Ok(())
    }

    /// åŠŸèƒ½ä¹ï¼šè¯»å–é¡¹ç›®çš„ rmmproject.toml
    pub fn get_project_config(&self, project_path: &Path) -> Result<RmmProject> {
        let project_key = project_path.to_string_lossy().to_string();
        
        // æ£€æŸ¥ç¼“å­˜
        {
            let cache = self.project_cache.lock().unwrap();
            if let Some(cached) = cache.get(&project_key) {
                if !cached.is_expired() {
                    return Ok(cached.data.clone());
                }
            }
        }

        let project_file = project_path.join("rmmproject.toml");
        let content = fs::read_to_string(&project_file)
            .with_context(|| format!("Failed to read rmmproject.toml from {}", project_file.display()))?;
        
        let project: RmmProject = toml::from_str(&content)
            .with_context(|| "Failed to parse rmmproject.toml")?;

        // æ›´æ–°ç¼“å­˜
        {
            let mut cache = self.project_cache.lock().unwrap();
            cache.insert(project_key, CacheItem::new(project.clone(), self.cache_ttl));
        }

        Ok(project)
    }

    /// æ›´æ–°é¡¹ç›®é…ç½®
    #[allow(dead_code)]
    pub fn update_project_config(&self, project_path: &Path, project: &RmmProject) -> Result<()> {
        let project_file = project_path.join("rmmproject.toml");
        
        let content = toml::to_string_pretty(project)
            .with_context(|| "Failed to serialize project config")?;
        
        fs::write(&project_file, content)
            .with_context(|| format!("Failed to write rmmproject.toml to {}", project_file.display()))?;

        // æ›´æ–°ç¼“å­˜
        let project_key = project_path.to_string_lossy().to_string();
        {
            let mut cache = self.project_cache.lock().unwrap();
            cache.insert(project_key, CacheItem::new(project.clone(), self.cache_ttl));
        }

        Ok(())
    }

    /// åŠŸèƒ½åï¼šè¯»å–é¡¹ç›®ç›®å½•ä¸‹çš„ module.propï¼ˆä»¥ TOML æ ¼å¼ï¼‰
    pub fn get_module_prop(&self, project_path: &Path) -> Result<ModuleProp> {
        let prop_file = project_path.join("module.prop");
        let content = fs::read_to_string(&prop_file)
            .with_context(|| format!("Failed to read module.prop from {}", prop_file.display()))?;
        
        let prop: ModuleProp = toml::from_str(&content)
            .with_context(|| "Failed to parse module.prop")?;

        Ok(prop)
    }

    /// å†™å…¥é¡¹ç›®ç›®å½•ä¸‹çš„ module.prop
    pub fn update_module_prop(&self, project_path: &Path, prop: &ModuleProp) -> Result<()> {
        let prop_file = project_path.join("module.prop");
        
        let content = toml::to_string_pretty(prop)
            .with_context(|| "Failed to serialize module prop")?;
        
        fs::write(&prop_file, content)
            .with_context(|| format!("Failed to write module.prop to {}", prop_file.display()))?;

        Ok(())
    }

    /// è¯»å–é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ .rmmp/Rmake.toml æ–‡ä»¶
    pub fn get_rmake_config(&self, project_path: &Path) -> Result<RmakeConfig> {
        let rmake_file = project_path.join(".rmmp").join("Rmake.toml");
        let content = fs::read_to_string(&rmake_file)
            .with_context(|| format!("Failed to read Rmake.toml from {}", rmake_file.display()))?;
        
        let rmake: RmakeConfig = toml::from_str(&content)
            .with_context(|| "Failed to parse Rmake.toml")?;

        Ok(rmake)
    }    /// å†™å…¥é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ .rmmp/Rmake.toml æ–‡ä»¶
    #[allow(dead_code)]
    pub fn update_rmake_config(&self, project_path: &Path, rmake: &RmakeConfig) -> Result<()> {
        let rmmp_dir = project_path.join(".rmmp");
        let rmake_file = rmmp_dir.join("Rmake.toml");
        
        // ç¡®ä¿ .rmmp ç›®å½•å­˜åœ¨
        fs::create_dir_all(&rmmp_dir)
            .with_context(|| format!("Failed to create .rmmp directory at {}", rmmp_dir.display()))?;
        
        let content = toml::to_string_pretty(rmake)
            .with_context(|| "Failed to serialize Rmake config")?;
        
        fs::write(&rmake_file, content)
            .with_context(|| format!("Failed to write Rmake.toml to {}", rmake_file.display()))?;

        Ok(())
    }

    /// è¿è¡ŒRmake.tomlä¸­å®šä¹‰çš„è„šæœ¬
    pub fn run_rmake_script(&self, project_path: &Path, script_name: &str) -> Result<()> {
        use std::process::Command;
        
        // è¯»å–Rmakeé…ç½®
        let rmake = self.get_rmake_config(project_path)?;
        
        // æ£€æŸ¥è„šæœ¬æ˜¯å¦å­˜åœ¨
        let scripts = rmake.build.scripts.as_ref()
            .ok_or_else(|| anyhow::anyhow!("Rmake.tomlä¸­æ²¡æœ‰å®šä¹‰scriptséƒ¨åˆ†"))?;
        
        let script_command = scripts.get(script_name)
            .ok_or_else(|| anyhow::anyhow!("è„šæœ¬ '{}' æœªæ‰¾åˆ°", script_name))?;
        
        println!("ğŸš€ æ‰§è¡Œè„šæœ¬: {}", script_name);        println!("ğŸ“‹ å‘½ä»¤: {}", script_command);        
        // æ‰§è¡Œå‘½ä»¤ - ä½¿ç”¨ç³»ç»Ÿé»˜è®¤ç»ˆç«¯é¿å…UNCè·¯å¾„é—®é¢˜
        let mut cmd = if cfg!(target_os = "windows") {
            // Windows: ä½¿ç”¨PowerShellé¿å…UNCè·¯å¾„é—®é¢˜
            let mut cmd = Command::new("powershell");
            cmd.arg("-Command")
               .arg(&format!("cd '{}'; {}", project_path.display(), script_command));
            cmd
        } else {
            // Unix/Linux: ä½¿ç”¨sh
            let mut cmd = Command::new("sh");
            cmd.arg("-c").arg(script_command);
            cmd.current_dir(project_path);
            cmd
        };
        
        let output = cmd.output()
            .with_context(|| format!("æ‰§è¡Œè„šæœ¬ '{}' å¤±è´¥", script_name))?;
        
        // è¾“å‡ºç»“æœ
        if !output.stdout.is_empty() {
            print!("{}", String::from_utf8_lossy(&output.stdout));
        }
        
        if !output.stderr.is_empty() {
            eprint!("{}", String::from_utf8_lossy(&output.stderr));
        }
        
        // æ£€æŸ¥æ‰§è¡Œç»“æœ
        if !output.status.success() {
            return Err(anyhow::anyhow!(
                "è„šæœ¬ '{}' æ‰§è¡Œå¤±è´¥ï¼Œé€€å‡ºä»£ç : {:?}", 
                script_name, 
                output.status.code()
            ));
        }
        
        println!("âœ… è„šæœ¬ '{}' æ‰§è¡ŒæˆåŠŸ", script_name);
        Ok(())
    }
    
    /// åˆ—å‡ºRmake.tomlä¸­æ‰€æœ‰å¯ç”¨çš„è„šæœ¬
    pub fn list_rmake_scripts(&self, project_path: &Path) -> Result<Vec<String>> {
        let rmake = self.get_rmake_config(project_path)?;
        
        let scripts = rmake.build.scripts.as_ref()
            .ok_or_else(|| anyhow::anyhow!("Rmake.tomlä¸­æ²¡æœ‰å®šä¹‰scriptséƒ¨åˆ†"))?;
        
        Ok(scripts.keys().cloned().collect())
    }

    /// æ¸…ç†è¿‡æœŸç¼“å­˜
    pub fn cleanup_expired_cache(&self) {
        // æ¸…ç† meta ç¼“å­˜
        {
            let mut cache = self.meta_cache.lock().unwrap();
            if let Some(cached) = cache.as_ref() {
                if cached.is_expired() {
                    *cache = None;
                }
            }
        }

        // æ¸…ç†é¡¹ç›®ç¼“å­˜
        {
            let mut cache = self.project_cache.lock().unwrap();
            cache.retain(|_, cached| !cached.is_expired());
        }
    }

    /// è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
    pub fn get_cache_stats(&self) -> (bool, usize) {
        let meta_cached = {
            let cache = self.meta_cache.lock().unwrap();
            cache.is_some() && !cache.as_ref().unwrap().is_expired()
        };

        let project_count = {
            let cache = self.project_cache.lock().unwrap();
            cache.len()
        };

        (meta_cached, project_count)
    }
}

impl Default for RmmCore {
    fn default() -> Self {
        Self::new()
    }
}

// å·¥å…·å‡½æ•°
impl RmmCore {
    /// åˆ›å»ºé»˜è®¤çš„ meta.toml é…ç½®
    #[allow(dead_code)]
    pub fn create_default_meta(&self, email: &str, username: &str, version: &str) -> MetaConfig {
        MetaConfig {
            email: email.to_string(),
            username: username.to_string(),
            version: version.to_string(),
            projects: HashMap::new(),
        }
    }

    /// åˆ›å»ºé»˜è®¤çš„é¡¹ç›®é…ç½®
    #[allow(dead_code)]
    pub fn create_default_project(&self, id: &str, username: &str, email: &str) -> RmmProject {
        RmmProject {
            project: ProjectInfo {
                id: id.to_string(),
                description: format!("RMMé¡¹ç›® {}", id),
                readme: "README.MD".to_string(),
                changelog: "CHANGELOG.MD".to_string(),
                license: "LICENSE".to_string(),
                dependencies: vec![],
                scripts: Some({
                    let mut scripts = HashMap::new();
                    scripts.insert("hello".to_string(), "echo 'hello world!'".to_string());
                    scripts
                }),
            },
            authors: vec![Author {
                name: username.to_string(),
                email: email.to_string(),
            }],
            urls: Some(UrlsInfo {
                github: "https://github.com/YOUR_USERNAME/YOUR_REPOSITORY".to_string(),
            }),
            build_system: Some(BuildSystem {
                requires: vec!["rmm>=0.3.0".to_string()],
                build_backend: "rmm".to_string(),
            }),
            tool: None,
        }
    }

    /// åˆ›å»ºé»˜è®¤çš„ module.prop
    #[allow(dead_code)]
    pub fn create_default_module_prop(&self, id: &str, username: &str) -> ModuleProp {
        ModuleProp {
            id: id.to_string(),
            name: id.to_string(),
            version: "v0.1.0".to_string(),
            version_code: "1000000".to_string(),
            author: username.to_string(),
            description: format!("RMMé¡¹ç›® {}", id),
            update_json: "https://raw.githubusercontent.com/YOUR_USERNAME/YOUR_REPOSITORY/main/update.json".to_string(),
        }
    }    /// åˆ›å»ºé»˜è®¤çš„ Rmake.toml é…ç½®
    #[allow(dead_code)]
    pub fn create_default_rmake(&self) -> RmakeConfig {
        let mut default_scripts = HashMap::new();        // æ·»åŠ è·¨å¹³å°é»˜è®¤è„šæœ¬
        if cfg!(target_os = "windows") {
            default_scripts.insert("clean".to_string(), "Remove-Item '.rmmp\\build' -Recurse -Force -ErrorAction SilentlyContinue; Remove-Item '.rmmp\\dist' -Recurse -Force -ErrorAction SilentlyContinue; New-Item -Path '.rmmp\\build' -ItemType Directory -Force; New-Item -Path '.rmmp\\dist' -ItemType Directory -Force".to_string());
        } else {
            default_scripts.insert("clean".to_string(), "rm -rf .rmmp/build/* .rmmp/dist/*".to_string());
        }
        
        // å®‰è£…æ¨¡å—çš„æ‰‹åŠ¨æ–¹å¼å‚è€ƒï¼š
        // /data/adb/magisk --install-module xxx
        // /data/adb/ksud module install xxx
        // /data/adb/apd module install xxx
        
        RmakeConfig {
            build: BuildConfig {
                include: vec!["../.gitignore".to_string()],
                exclude: vec![
                    ".git".to_string(), 
                    ".rmmp".to_string(), 
                    "*.tmp".to_string(), 
                    "*.log".to_string()
                ],
                prebuild: vec!["echo 'Starting build'".to_string()],
                build: vec!["rmm".to_string()],
                postbuild: vec!["echo 'Build completed'".to_string()],
                src: Some(SrcConfig {
                    include: vec!["# æºä»£ç é¢å¤–åŒ…å«çš„æ–‡ä»¶ï¼Œå¦‚ï¼š\"docs/\"".to_string()],
                    exclude: vec![
                        ".git".to_string(),
                        "*.tmp".to_string(),
                        "*.log".to_string(),
                        "node_modules".to_string(),
                    ],
                }),
                scripts: Some(default_scripts),
            },
        }
    }
}

impl RmmCore {/// æ£€æµ‹ç»™å®šè·¯å¾„æ˜¯å¦åœ¨ Git ä»“åº“ä¸­ï¼Œå¹¶è¿”å›è¯¦ç»†ä¿¡æ¯
    pub fn get_git_info(&self, path: &Path) -> Result<GitInfo> {
        let canonical_path = path.canonicalize()
            .map_err(|e| anyhow::anyhow!("æ— æ³•è·å–è·¯å¾„çš„ç»å¯¹è·¯å¾„: {}", e))?;
        
        // æ£€æŸ¥ç¼“å­˜
        {
            let cache = self.git_cache.lock().unwrap();
            if let Some((git_info, cached_time)) = cache.get(&canonical_path) {
                if cached_time.elapsed() < self.cache_ttl {
                    return Ok(git_info.clone());
                }
            }
        }
        
        let git_info = self.analyze_git_info(&canonical_path)?;
        
        // æ›´æ–°ç¼“å­˜
        {
            let mut cache = self.git_cache.lock().unwrap();
            cache.insert(canonical_path, (git_info.clone(), Instant::now()));
        }
        
        Ok(git_info)
    }
    
    /// åˆ†æè·¯å¾„çš„ Git ä¿¡æ¯
    fn analyze_git_info(&self, path: &Path) -> Result<GitInfo> {
        let mut current_path = path.to_path_buf();
        let original_path = path.to_path_buf();
        
        // å‘ä¸Šéå†å¯»æ‰¾ .git æ–‡ä»¶å¤¹
        loop {
            let git_path = current_path.join(".git");
            if git_path.exists() {
                let relative_path = original_path.strip_prefix(&current_path)
                    .unwrap_or(Path::new(""))
                    .to_path_buf();
                
                let mut git_info = GitInfo {
                    repo_root: current_path.clone(),
                    relative_path,
                    branch: String::new(),
                    remote_url: None,
                    has_uncommitted_changes: false,
                    last_commit_hash: None,
                    last_commit_message: None,
                };
                
                // è¯»å–æ›´å¤š Git ä¿¡æ¯
                self.read_git_details(&current_path, &mut git_info)?;
                
                return Ok(git_info);
            }
            
            match current_path.parent() {
                Some(parent) => current_path = parent.to_path_buf(),
                None => break,
            }
        }
        
        // æ²¡æœ‰æ‰¾åˆ° Git ä»“åº“
        Ok(GitInfo::default())
    }
    
    /// è¯»å– Git ä»“åº“çš„è¯¦ç»†ä¿¡æ¯
    fn read_git_details(&self, git_root: &Path, git_info: &mut GitInfo) -> Result<()> {
        let git_path = git_root.join(".git");
        
        // è¯»å–å½“å‰åˆ†æ”¯
        if let Ok(head_content) = fs::read_to_string(git_path.join("HEAD")) {
            if let Some(branch) = head_content.strip_prefix("ref: refs/heads/") {
                git_info.branch = branch.trim().to_string();
            }
        }
        
        // è¯»å–è¿œç¨‹ä»“åº“ URL
        if let Ok(config_content) = fs::read_to_string(git_path.join("config")) {
            git_info.remote_url = self.parse_git_remote_url(&config_content);
        }
        
        // æ£€æŸ¥æ˜¯å¦æœ‰æœªæäº¤çš„æ›´æ”¹ï¼ˆç®€å•æ£€æŸ¥ï¼‰
        git_info.has_uncommitted_changes = self.check_git_status(git_root)?;
        
        // è·å–æœ€åä¸€æ¬¡æäº¤ä¿¡æ¯
        let (last_commit_hash, last_commit_message) = self.get_last_commit_info(git_root)?;
        git_info.last_commit_hash = last_commit_hash;
        git_info.last_commit_message = last_commit_message;
        
        Ok(())
    }
    
    /// è§£æ Git é…ç½®ä¸­çš„è¿œç¨‹ URL
    fn parse_git_remote_url(&self, config_content: &str) -> Option<String> {
        for line in config_content.lines() {
            let line = line.trim();
            if line.starts_with("url = ") {
                return Some(line.strip_prefix("url = ")?.to_string());
            }
        }
        None
    }
    
    /// æ£€æŸ¥ Git ä»“åº“çŠ¶æ€ï¼ˆç®€åŒ–ç‰ˆï¼‰
    fn check_git_status(&self, git_root: &Path) -> Result<bool> {
        let git_path = git_root.join(".git");
        
        // æ£€æŸ¥ index æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ€è¿‘è¢«ä¿®æ”¹
        let index_path = git_path.join("index");
        if let Ok(metadata) = fs::metadata(&index_path) {
            if let Ok(modified) = metadata.modified() {
                if let Ok(elapsed) = modified.elapsed() {
                    // å¦‚æœ index æ–‡ä»¶åœ¨æœ€è¿‘ 1 å°æ—¶å†…è¢«ä¿®æ”¹ï¼Œå¯èƒ½æœ‰æœªæäº¤çš„æ›´æ”¹
                    return Ok(elapsed < Duration::from_secs(3600));
                }
            }
        }
        
        // æ£€æŸ¥å·¥ä½œç›®å½•ä¸­æ˜¯å¦æœ‰æ–°æ–‡ä»¶æˆ–ä¿®æ”¹çš„æ–‡ä»¶
        // è¿™é‡Œåšç®€åŒ–å¤„ç†ï¼Œåªæ£€æŸ¥ä¸€äº›å¸¸è§çš„æŒ‡ç¤ºå™¨
        Ok(false)
    }
    
    /// è·å–æœ€åä¸€æ¬¡æäº¤ä¿¡æ¯
    fn get_last_commit_info(&self, git_root: &Path) -> Result<(Option<String>, Option<String>)> {
        let repo = Repository::open(git_root)
            .with_context(|| format!("Failed to open Git repository at {}", git_root.display()))?;
        
        let head = repo.head()
            .with_context(|| "Failed to get HEAD reference")?;
        
        if let Some(oid) = head.target() {
            let commit = repo.find_commit(oid)
                .with_context(|| "Failed to find commit")?;
            
            let hash = oid.to_string();
            let message = commit.message().unwrap_or("").to_string();
            
            Ok((Some(hash), Some(message)))
        } else {
            Ok((None, None))
        }
    }
    
    /// è·å–é¡¹ç›®çš„ Git ä¿¡æ¯
    #[allow(dead_code)]
    pub fn get_project_git_info(&self, project_name: &str) -> Result<Option<GitInfo>> {
        if let Some(project_path) = self.get_project_path(project_name)? {
            Ok(Some(self.get_git_info(&project_path)?))
        } else {
            Ok(None)
        }
    }
    
    /// è·å–æ‰€æœ‰é¡¹ç›®çš„ Git ä¿¡æ¯
    #[allow(dead_code)]
    pub fn get_all_projects_git_info(&self) -> Result<HashMap<String, GitInfo>> {
        let meta = self.get_meta_config()?;
        let mut git_info_map = HashMap::new();
        
        for (project_name, _) in &meta.projects {
            if let Ok(Some(git_info)) = self.get_project_git_info(project_name) {
                git_info_map.insert(project_name.clone(), git_info);
            }
        }
        
        Ok(git_info_map)
    }
      /// æ£€æŸ¥é¡¹ç›®æ˜¯å¦åœ¨ Git ä»“åº“ä¸­
    #[allow(dead_code)]
    pub fn is_project_in_git(&self, project_name: &str) -> Result<bool> {
        if let Ok(Some(_git_info)) = self.get_project_git_info(project_name) {
            Ok(true)
        } else {
            Ok(false)
        }
    }
      /// è·å–é¡¹ç›®ç›¸å¯¹äº Git æ ¹ç›®å½•çš„è·¯å¾„
    #[allow(dead_code)]
    pub fn get_project_git_relative_path(&self, project_name: &str) -> Result<Option<PathBuf>> {
        if let Ok(Some(git_info)) = self.get_project_git_info(project_name) {
            return Ok(Some(git_info.relative_path));
        }
        Ok(None)
    }
    
    /// æ¸…ç† Git ç¼“å­˜
    pub fn clear_git_cache(&self) {
        let mut cache = self.git_cache.lock().unwrap();
        cache.clear();
    }
    
    /// æ¸…ç†è¿‡æœŸçš„ Git ç¼“å­˜é¡¹
    #[allow(dead_code)]
    pub fn cleanup_expired_git_cache(&self) {
        let mut cache = self.git_cache.lock().unwrap();
        let now = Instant::now();
        cache.retain(|_, (_, cached_time)| now.duration_since(*cached_time) < self.cache_ttl);
    }
}

impl RmmCore {    /// ä»metaé…ç½®ä¸­ç§»é™¤é¡¹ç›®
    pub fn remove_project_from_meta(&self, project_name: &str) -> Result<bool> {
        let mut meta = self.get_meta_config()?;
        let removed = meta.projects.remove(project_name).is_some();
        if removed {
            self.update_meta_config(&meta)?;
        }
        Ok(removed)
    }

    /// ä»metaé…ç½®ä¸­ç§»é™¤å¤šä¸ªé¡¹ç›®
    pub fn remove_projects_from_meta(&self, project_names: &[&str]) -> Result<Vec<String>> {
        let mut meta = self.get_meta_config()?;
        let mut removed = Vec::new();
        
        for &project_name in project_names {
            if meta.projects.remove(project_name).is_some() {
                removed.push(project_name.to_string());
            }
        }
        
        if !removed.is_empty() {
            self.update_meta_config(&meta)?;
        }
        
        Ok(removed)
    }

    /// ç§»é™¤æ‰€æœ‰æ— æ•ˆçš„é¡¹ç›®
    pub fn remove_invalid_projects(&self) -> Result<Vec<String>> {
        let validity = self.check_projects_validity()?;
        let invalid_projects: Vec<&str> = validity.iter()
            .filter(|(_, is_valid)| !**is_valid)
            .map(|(name, _)| name.as_str())
            .collect();
        
        self.remove_projects_from_meta(&invalid_projects)
    }    /// æ¸…ç†æ‰€æœ‰ç¼“å­˜
    pub fn clear_all_cache(&self) {
        // ğŸ”§ ä¿®å¤ï¼šæ¸…ç†æ‰€æœ‰ç±»å‹çš„ç¼“å­˜
        {
            let mut cache = self.meta_cache.lock().unwrap();
            *cache = None;
        }
        {
            let mut cache = self.project_cache.lock().unwrap();
            cache.clear();
        }
        self.clear_git_cache();
    }    /// æ¸…é™¤æ‰€æœ‰ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°è¯»å–
    #[allow(dead_code)]
    pub fn clear_cache(&self) {
        {
            let mut cache = self.meta_cache.lock().unwrap();
            *cache = None;
        }
        {
            let mut cache = self.project_cache.lock().unwrap();
            cache.clear();
        }
        {
            let mut cache = self.git_cache.lock().unwrap();
            cache.clear();
        }
    }
}

/// éªŒè¯é¡¹ç›®åç§°æ˜¯å¦ç¬¦åˆè§„èŒƒ
/// è§„åˆ™ï¼š^[a-zA-Z][a-zA-Z0-9._-]+$
/// - å¿…é¡»ä»¥å­—æ¯å¼€å¤´
/// - åç»­å­—ç¬¦å¯ä»¥æ˜¯å­—æ¯ã€æ•°å­—ã€ç‚¹ã€ä¸‹åˆ’çº¿æˆ–è¿å­—ç¬¦
fn is_valid_project_name(name: &str) -> bool {
    use std::sync::OnceLock;
    use regex::Regex;
    
    // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨é™æ€æ­£åˆ™è¡¨è¾¾å¼ï¼Œé¿å…é‡å¤ç¼–è¯‘
    static PROJECT_NAME_REGEX: OnceLock<Regex> = OnceLock::new();
    
    let regex = PROJECT_NAME_REGEX.get_or_init(|| {
        Regex::new(r"^[a-zA-Z][a-zA-Z0-9._-]+$").expect("Invalid regex pattern")
    });
    
    // éªŒè¯åç§°é•¿åº¦å’Œæ ¼å¼
    name.len() >= 2 && name.len() <= 100 && regex.is_match(name)
}

